{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FeedForwardNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPATHYA38/0q1koM8kjsvlT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andy311p/Udemy_deep_learning_pytorch/blob/master/FeedForwardNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxgJo0p3yDCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "train_dataset = dsets.MNIST(root='./data', \n",
        "                            train=True,\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "test_dataset = dsets.MNIST(root='./data', \n",
        "                            train=False,\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfiHDftkyalx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = int(n_iters / (len(train_dataset)/batch_size))\n",
        "\n",
        "#iterable object\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKYWJNDRzEh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeedForwardNeuralNetModel(nn.Module):\n",
        "  def __init__(self,input_dim,hidden_dim,output_dim):\n",
        "    super(FeedForwardNeuralNetModel,self).__init__()\n",
        "    #Linear function\n",
        "    self.fc1 = nn.Linear(input_dim,hidden_dim)\n",
        "\n",
        "    #non Linear function\n",
        "    #self.sigmoid = nn.Sigmoid()\n",
        "    #self.tanh = nn.Tanh()\n",
        "    self.relu1 = nn.ReLU()\n",
        "\n",
        "    #adding second non linear layer\n",
        "    self.fc2 = nn.Linear(hidden_dim,hidden_dim)\n",
        "    self.relu2 = nn.ReLU()\n",
        "\n",
        "    #Linear function (read out)\n",
        "    self.fc3 = nn.Linear(hidden_dim,output_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.fc1(x)\n",
        "    out = self.relu1(out)\n",
        "    out = self.fc2(out)\n",
        "    out = self.relu2(out)\n",
        "    out = self.fc3(out)\n",
        "    return out  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOzW6AWc0hOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#image size\n",
        "input_dim = 28*28\n",
        "hidden_dim = 100\n",
        "#num of classes(digits 0-9)\n",
        "output_dim=10\n",
        "\n",
        "model = FeedForwardNeuralNetModel(input_dim,hidden_dim,output_dim)\n",
        "#computes the softmax automatically\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.1\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmOhleSr2-AB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4e07ad65-58be-4efe-db16-a0abd38054a2"
      },
      "source": [
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images,labels) in enumerate(train_loader):\n",
        "    images = Variable(images.view(-1,28*28))\n",
        "    labels = Variable(labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    iter += 1\n",
        "    #every 500 iteration calculate accuracy\n",
        "    if iter % 500 == 0:\n",
        "      correct = 0.0\n",
        "      total = 0.0\n",
        "      #calc accuracy on test data\n",
        "      for images, labels in test_loader:\n",
        "        images = Variable(images.view(-1,28*28))\n",
        "        outputs = model(images)\n",
        "        _, predictions = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predictions == labels).sum()\n",
        "\n",
        "      accuracy = 100 * correct / total\n",
        "      print('iteration: {}. loss: {} Accuracy: {}'.format(iter, loss.data,accuracy)) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration: 500. loss: 0.29871857166290283 Accuracy: 91.58999633789062\n",
            "iteration: 1000. loss: 0.13758662343025208 Accuracy: 93.2699966430664\n",
            "iteration: 1500. loss: 0.31436678767204285 Accuracy: 94.9000015258789\n",
            "iteration: 2000. loss: 0.09019793570041656 Accuracy: 95.9000015258789\n",
            "iteration: 2500. loss: 0.14827848970890045 Accuracy: 96.18000030517578\n",
            "iteration: 3000. loss: 0.14193996787071228 Accuracy: 96.5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}